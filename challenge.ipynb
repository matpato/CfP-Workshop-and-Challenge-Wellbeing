{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Workshop and Challenge on Detection of Stress and Mental Health Using Wearable Sensors\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#1\">1. Data retrieval and cleaning</a></li>\n",
    "</ul>\n",
    "   \n",
    "<ul>\n",
    "   <li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#1.1\">1.1. Import libraries</a></li>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "   <li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#1.2\">1.2. Retrieve a sample of the SMILE dataset</a></li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<ul>\n",
    "   <li><a href=\"#2\">2. Data statistics</a></li>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "   <li><a href=\"#3\">3. Machine learning classifiers</a></li>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "   <li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#3.1\">3.1. Import libraries</a></li>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "   <li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#3.2\">3.2. Import predefined functions</a></li>\n",
    "</ul>\n",
    "<ul>\n",
    "   <li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#3.3\">3.3. Classification</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "\n",
    "## 1. Data retrieval and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "### 1.1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "### 1.2. Retrieve a sample of the SMILE dataset\n",
    "\n",
    "The SMILE dataset was collected from 45 healthy adult participants (39 females and 6 males) in Belgium. The average age of participants was 24.5 years old, with a standard deviation of 3.0 years. Each participant contributed to an average of 8.7 days of data. Two types of wearable sensors were used for data collection. One was a wrist-worn device (Chillband, IMEC, Belgium) designed for the measurement of skin conductance (SC), ST, and acceleration data (ACC). The second sensor was a chest patch (Health Patch, IMEC, Belgium) to measure ECG and ACC. It contains a sensor node designed to monitor ECG at 256 Hz and ACC at 32 Hz continuously throughout the study period. Participants could remove the sensors while showering or before doing intense exercises. Also, participants received notifications on their mobile phones to report their momentary stress levels daily. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://compwell.rice.edu/workshops/embc2022/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('data/dataset_smile_challenge.npy', allow_pickle=True).item()\n",
    "#     dict\n",
    "#         dictionary with dataset, with keys:\n",
    "#          * `train`\n",
    "#           * `deep_features`\n",
    "#            * `ECG_features_C`\n",
    "#            * `ECG_features_T`\n",
    "#            * `masking`\n",
    "#           * `hand_crafted_features`\n",
    "#            * `ECG_features`\n",
    "#            * `ECG_masking`\n",
    "#            * `GSR_features`\n",
    "#            * `GSR_masking`\n",
    "#           * `labels`\n",
    "#          * `test`\n",
    "#           * Same structure as `train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the contents of the dataset directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0bd8a",
   "metadata": {},
   "source": [
    "<img src = \"img/SMILE_dataset_features_3.png\" width = \"500\" height = \"400\" >\n",
    "\n",
    "[Souce: Click here](https://compwell.rice.edu/workshops/embc2022/challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training and testing data:\n",
    "dataset_train = dataset['train']\n",
    "dataset_test = dataset['test']\n",
    "# for deep features.\n",
    "deep_features = dataset_train['deep_features']\n",
    "# conv1d backbone based features for ECG signal.\n",
    "deep_features['ECG_features_C'] \n",
    "# transformer backbone base features for ECG signal  \n",
    "deep_features['ECG_features_T']   \n",
    "# for hand-crafted features.\n",
    "handcrafted_features_train = dataset_train['hand_crafted_features']\n",
    "handcrafted_features_test = dataset_test['hand_crafted_features']\n",
    "# handcrafted features for ECG signal\n",
    "handcrafted_features_train['ECG_features'] \n",
    "handcrafted_features_test['ECG_features']\n",
    "# handcrafted features for GSR signal. \n",
    "handcrafted_features_train['GSR_features'] \n",
    "handcrafted_features_test['GSR_features']\n",
    "# for labels.\n",
    "labels_train = dataset_train['labels']  \n",
    "labels_test = dataset_test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a DataFrame with the contents of the metadata file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. Data statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (2070, 60, 8)\n",
      "test: (986, 60, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"train: {dataset['train']['hand_crafted_features']['ECG_features'].shape}\")\n",
    "print(\n",
    "    f\"test: {dataset['test']['hand_crafted_features']['ECG_features'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SMILE dataset as a dictionary from npy file.\n",
    "Each feature matrix has 3 dimensions:\n",
    "* sequence (of 60 minutes)\n",
    "* window (5 minute with 4 min overlap)\n",
    "* feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ECG Features\n",
    "* feature and label vector construction\n",
    "* creation of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represents the features extracted from one window of the sequence (corresponding to 5 minutes)\n",
    "dataset['test']['hand_crafted_features']['ECG_features'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with features\n",
    "# Train dataset\n",
    "nfeatures = len(dataset['train']['hand_crafted_features']['ECG_features'][0][0])\n",
    "n = len(dataset['train']['hand_crafted_features']['ECG_features']) * \\\n",
    "    len(dataset['train']['hand_crafted_features']['ECG_features'])\n",
    "# \n",
    "handcrafted_features_train=np.zeros((n,nfeatures)) # X\n",
    "handcrafted_labels_train = np.zeros(n)  # y\n",
    "#\n",
    "count=0\n",
    "for i in range(len(dataset['train']['hand_crafted_features']['ECG_features'])):\n",
    "    for j in range(len(dataset['train']['hand_crafted_features']['ECG_features'][i])):\n",
    "        if(np.sum(np.isnan(dataset['train']['hand_crafted_features']['ECG_features'][i][j])) == 0):\n",
    "            # remove NAN\n",
    "            handcrafted_features_train[count,\n",
    "                                       0:nfeatures] = dataset['train']['hand_crafted_features']['ECG_features'][i][j]\n",
    "            handcrafted_labels_train[count] = dataset['train']['labels'][i]\n",
    "            count=count+1   \n",
    "# Remove last values from the array\n",
    "data_train = handcrafted_features_train\n",
    "data_train[:-(n-count), :].shape\n",
    "## Labels\n",
    "data_train_label = handcrafted_labels_train\n",
    "data_train_label[:-(n-count)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "nfeatures = len(dataset['test']['hand_crafted_features']['ECG_features'][0][0])\n",
    "n = len(dataset['test']['hand_crafted_features']['ECG_features']) * \\\n",
    "    len(dataset['test']['hand_crafted_features']['ECG_features'][0])\n",
    "# \n",
    "handcrafted_features_test=np.zeros((n,nfeatures)) #X\n",
    "handcrafted_labels_test = np.zeros(n)  # y\n",
    "\n",
    "count=0\n",
    "for i in range(len(dataset['test']['hand_crafted_features']['ECG_features'])):\n",
    "    #print(dataset['test']['hand_crafted_features']['ECG_features'][i])\n",
    "    for j in range(len(dataset['test']['hand_crafted_features']['ECG_features'][i])):\n",
    "        if(np.sum(np.isnan(dataset['test']['hand_crafted_features']['ECG_features'][i][j])) == 0):\n",
    "            # remove NAN\n",
    "            handcrafted_features_test[count,\n",
    "                                      0:nfeatures] = dataset['test']['hand_crafted_features']['ECG_features'][i][j]\n",
    "            handcrafted_labels_test[count] = dataset['test']['labels'][i]\n",
    "            count = count+1\n",
    "# Remove last values from the array\n",
    "data_test = handcrafted_features_test\n",
    "data_test[:-(n-count),:].shape  \n",
    "## Labels\n",
    "data_test_label = handcrafted_labels_test\n",
    "data_test_label[:-(n-count)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find max\n",
    "print(np.where(data_train_label == np.max(data_train_label)))\n",
    "## find min\n",
    "print(np.where(data_train_label==np.min(data_train_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find uniques\n",
    "np.unique(data_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "698b7509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145656</td>\n",
       "      <td>0.152954</td>\n",
       "      <td>0.029353</td>\n",
       "      <td>0.013258</td>\n",
       "      <td>0.487958</td>\n",
       "      <td>0.272209</td>\n",
       "      <td>0.149786</td>\n",
       "      <td>0.056021</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161642</td>\n",
       "      <td>0.037914</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.485591</td>\n",
       "      <td>0.273006</td>\n",
       "      <td>0.150057</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.102252</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.026775</td>\n",
       "      <td>0.469134</td>\n",
       "      <td>0.222267</td>\n",
       "      <td>0.105493</td>\n",
       "      <td>0.101103</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101629</td>\n",
       "      <td>0.007554</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.456785</td>\n",
       "      <td>0.069741</td>\n",
       "      <td>0.043349</td>\n",
       "      <td>0.124622</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084450</td>\n",
       "      <td>0.012880</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.039552</td>\n",
       "      <td>0.510779</td>\n",
       "      <td>0.250722</td>\n",
       "      <td>0.168897</td>\n",
       "      <td>0.120275</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.062490</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>0.015376</td>\n",
       "      <td>0.512783</td>\n",
       "      <td>0.264303</td>\n",
       "      <td>0.172324</td>\n",
       "      <td>0.024459</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.021252</td>\n",
       "      <td>0.121443</td>\n",
       "      <td>0.024277</td>\n",
       "      <td>0.013844</td>\n",
       "      <td>0.507665</td>\n",
       "      <td>0.265297</td>\n",
       "      <td>0.176635</td>\n",
       "      <td>0.018308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.025347</td>\n",
       "      <td>0.076508</td>\n",
       "      <td>0.017720</td>\n",
       "      <td>0.016150</td>\n",
       "      <td>0.500325</td>\n",
       "      <td>0.267553</td>\n",
       "      <td>0.180807</td>\n",
       "      <td>0.023047</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.026834</td>\n",
       "      <td>0.017419</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.500671</td>\n",
       "      <td>0.261399</td>\n",
       "      <td>0.180753</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.048197</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>0.434076</td>\n",
       "      <td>0.107901</td>\n",
       "      <td>0.073289</td>\n",
       "      <td>0.055120</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0  0.145656  0.152954  0.029353  0.013258  0.487958  0.272209  0.149786   \n",
       "1  0.161642  0.037914  0.008152  0.015038  0.485591  0.273006  0.150057   \n",
       "2  0.102252  0.007947  0.003004  0.026775  0.469134  0.222267  0.105493   \n",
       "3  0.101629  0.007554  0.003805  0.035377  0.456785  0.069741  0.043349   \n",
       "4  0.084450  0.012880  0.007234  0.039552  0.510779  0.250722  0.168897   \n",
       "5  0.014152  0.062490  0.013785  0.015376  0.512783  0.264303  0.172324   \n",
       "6  0.021252  0.121443  0.024277  0.013844  0.507665  0.265297  0.176635   \n",
       "7  0.025347  0.076508  0.017720  0.016150  0.500325  0.267553  0.180807   \n",
       "8  0.026834  0.017419  0.004964  0.020146  0.500671  0.261399  0.180753   \n",
       "9  0.048197  0.010363  0.004642  0.031593  0.434076  0.107901  0.073289   \n",
       "\n",
       "         F8  Label  \n",
       "0  0.056021    0.0  \n",
       "1  0.061644    0.0  \n",
       "2  0.101103    0.0  \n",
       "3  0.124622    0.0  \n",
       "4  0.120275    0.0  \n",
       "5  0.024459    0.0  \n",
       "6  0.018308    0.0  \n",
       "7  0.023047    0.0  \n",
       "8  0.032929    0.0  \n",
       "9  0.055120    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a dataframe and save it in csv\n",
    "df_train = pd.DataFrame(data=np.column_stack((data_train, data_train_label)))\n",
    "df_train.columns = [\"F\"+str(i) for i in range(1, len(df_train.columns) + 1)]\n",
    "df_train.rename(columns={'F9': 'Label'}, inplace=True)\n",
    "df_train.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b925932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.076467</td>\n",
       "      <td>0.095720</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>0.896764</td>\n",
       "      <td>0.117228</td>\n",
       "      <td>0.068013</td>\n",
       "      <td>0.103472</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080711</td>\n",
       "      <td>0.110469</td>\n",
       "      <td>0.028849</td>\n",
       "      <td>0.014305</td>\n",
       "      <td>0.862462</td>\n",
       "      <td>0.151996</td>\n",
       "      <td>0.091932</td>\n",
       "      <td>0.105959</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079685</td>\n",
       "      <td>0.075259</td>\n",
       "      <td>0.021964</td>\n",
       "      <td>0.016503</td>\n",
       "      <td>0.793803</td>\n",
       "      <td>0.142263</td>\n",
       "      <td>0.100381</td>\n",
       "      <td>0.115297</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114616</td>\n",
       "      <td>0.047981</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>0.688007</td>\n",
       "      <td>0.128244</td>\n",
       "      <td>0.102531</td>\n",
       "      <td>0.061526</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.114824</td>\n",
       "      <td>0.018641</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>0.600439</td>\n",
       "      <td>0.106743</td>\n",
       "      <td>0.092132</td>\n",
       "      <td>0.073630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.111699</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.114999</td>\n",
       "      <td>0.542728</td>\n",
       "      <td>0.096495</td>\n",
       "      <td>0.086296</td>\n",
       "      <td>0.152916</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.182996</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>0.014673</td>\n",
       "      <td>0.125699</td>\n",
       "      <td>0.488070</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.047455</td>\n",
       "      <td>0.331250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.438657</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.093785</td>\n",
       "      <td>0.453511</td>\n",
       "      <td>0.019385</td>\n",
       "      <td>0.029299</td>\n",
       "      <td>0.503273</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.501287</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.073336</td>\n",
       "      <td>0.437255</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>0.024552</td>\n",
       "      <td>0.375109</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.228813</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.008132</td>\n",
       "      <td>0.063317</td>\n",
       "      <td>0.441105</td>\n",
       "      <td>0.057768</td>\n",
       "      <td>0.037015</td>\n",
       "      <td>0.199186</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0  0.076467  0.095720  0.019321  0.010044  0.896764  0.117228  0.068013   \n",
       "1  0.080711  0.110469  0.028849  0.014305  0.862462  0.151996  0.091932   \n",
       "2  0.079685  0.075259  0.021964  0.016503  0.793803  0.142263  0.100381   \n",
       "3  0.114616  0.047981  0.009772  0.010209  0.688007  0.128244  0.102531   \n",
       "4  0.114824  0.018641  0.009672  0.032108  0.600439  0.106743  0.092132   \n",
       "5  0.111699  0.007565  0.013751  0.114999  0.542728  0.096495  0.086296   \n",
       "6  0.182996  0.007383  0.014673  0.125699  0.488070  0.016631  0.047455   \n",
       "7  0.438657  0.007106  0.010648  0.093785  0.453511  0.019385  0.029299   \n",
       "8  0.501287  0.006591  0.007833  0.073336  0.437255  0.019230  0.024552   \n",
       "9  0.228813  0.008016  0.008132  0.063317  0.441105  0.057768  0.037015   \n",
       "\n",
       "         F8  Label  \n",
       "0  0.103472    0.0  \n",
       "1  0.105959    0.0  \n",
       "2  0.115297    0.0  \n",
       "3  0.061526    0.0  \n",
       "4  0.073630    0.0  \n",
       "5  0.152916    0.0  \n",
       "6  0.331250    0.0  \n",
       "7  0.503273    0.0  \n",
       "8  0.375109    0.0  \n",
       "9  0.199186    0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a dataframe and save it in csv\n",
    "df_test = pd.DataFrame(data=np.column_stack((data_test, data_test_label)))\n",
    "df_test.columns = [\"F\"+str(i) for i in range(1, len(df_test.columns) + 1)]\n",
    "df_test.rename(columns={'F9': 'Label'}, inplace=True)\n",
    "df_test.head(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('data/data_train.csv')\n",
    "df_test.to_csv('data/data_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 3. Machine learning classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958e385",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "### 3.1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "995fa2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random.mtrand\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import model_selection, metrics, tree\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, \\\n",
    "    AdaBoostClassifier, IsolationForest\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression, RFE\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62350f30",
   "metadata": {},
   "source": [
    "<a id=\"3.2\"></a>\n",
    "### 3.2. Import predefined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063bb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predefined_functions.logger import Logger, FeatureLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8aa32",
   "metadata": {},
   "source": [
    "<a id=\"3.3\"></a>\n",
    "### 3.3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3752c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_handcrafted_features = dataset['train']['hand_crafted_features']\n",
    "ds_train_labels = dataset['train']['labels']\n",
    "\n",
    "ds_handcrafted_masking = dataset['train']['hand_crafted_features']['ECG_masking']\n",
    "ds_deep_masking = dataset['train']['deep_features']['masking']\n",
    "\n",
    "ds_test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc18f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilteredDataset:\n",
    "\n",
    "    def __init__(self, ecgFeatures, gsrFeatures, labels):\n",
    "        self.ecgFeatures = ecgFeatures\n",
    "        self.gsrFeatures = gsrFeatures\n",
    "        self.labels = labels\n",
    "\n",
    "#Returns an array with the arrays to keep in all major arrays (labels and features)\n",
    "\n",
    "def filterZerosHandCraftedFeatures(handcraftedFeaturesDataset, handcraftedFeaturesLabels, filterZeros=True):\n",
    "\n",
    "    #retornar array com indexes a manter ? (Masi facil)\n",
    "    indexesToRemove = []\n",
    "\n",
    "    for key in handcraftedFeaturesDataset.keys():\n",
    "        if \"masking\" not in key:\n",
    "            continue\n",
    "        if not filterZeros:\n",
    "            continue\n",
    "        for i in range(len(handcraftedFeaturesDataset[key])):\n",
    "            if np.min(handcraftedFeaturesDataset[key][i]) == 0:\n",
    "                indexesToRemove.append(i)\n",
    "\n",
    "    indexesToKeep = range(len(handcraftedFeaturesLabels))\n",
    "    #else: indexesToKeep = np.delete(range(len(handcraftedFeaturesLabels)), np.unique(indexesToRemove))\n",
    "\n",
    "    return FilteredDataset(ecgFeatures=handcraftedFeaturesDataset['ECG_features'][indexesToKeep],\n",
    "                           gsrFeatures=handcraftedFeaturesDataset['GSR_features'][indexesToKeep],\n",
    "                           labels=handcraftedFeaturesLabels[indexesToKeep])\n",
    "\n",
    "\n",
    "def discretizeHandCraftedDataset(processedHandTrainDataset):\n",
    "    \n",
    "    n_entries = len(processedHandTrainDataset.labels)\n",
    "    nOfFeatures = 5\n",
    "    dataset_features = np.zeros((n_entries, nOfFeatures))\n",
    "    #Array positions\n",
    "    # 0 - mean minute hr\n",
    "    # 0 - mean gsr\n",
    "\n",
    "    for index_n_entries in range(n_entries):\n",
    "\n",
    "        dataset_features[index_n_entries] = [\n",
    "\n",
    "            ####### HR Features\n",
    "            # 0.20 , 0.006\n",
    "            np.nanmean(\n",
    "                [i[0] for i in processedHandTrainDataset.ecgFeatures[index_n_entries]]),\n",
    "            # np.nanpercentile([i[1] for i in processedHandTrainDataset.ecgFeatures[index_n_entries]], q=80),\n",
    "            # np.nanquantile([i[2] for i in processedHandTrainDataset.ecgFeatures[index_n_entries]],q=0.4),\n",
    "            # np.nansum([i[3] for i in processedHandTrainDataset.ecgFeatures[index_n_entries]]),\n",
    "            np.nanmean(\n",
    "                [i[7] for i in processedHandTrainDataset.ecgFeatures[index_n_entries]]),\n",
    "            # np.nanquantile([i[5] for i in processedHandTrainDataset.ecgFeatures[index_n_entries]], q=0.90),\n",
    "            ## 0.156 , 0.001\n",
    "            # np.nanpercentile([i[4] for i in processedHandTrainDataset.ecgFeatures[index_n_entries]], q=85), ## 0.148 , 0.014\n",
    "            # np.nanpercentile([i[6] for i in processedHandTrainDataset.ecgFeatures[index_n_entries]], q=10), #0.145, covariance :0.003\n",
    "            # np.nansum([i[4] for i in processedHandTrainDataset.ecgFeatures[index_n_entries]]), # 0.153 , 0.938\n",
    "\n",
    "            ######## GSR Features\n",
    "            np.nanvar(\n",
    "                [i[4] for i in processedHandTrainDataset.gsrFeatures[index_n_entries]]),\n",
    "            np.nanquantile([i[5] for i in processedHandTrainDataset.gsrFeatures[index_n_entries]],\n",
    "                           q=0.85) - np.nanquantile(\n",
    "                [i[0] for i in processedHandTrainDataset.gsrFeatures[index_n_entries]], q=0.15),\n",
    "            # -0.009, covariance :-0.000\n",
    "            # np.nanvar([i[4] for i in processedHandTrainDataset.gsrFeatures[index_n_entries]]),\n",
    "            # -0.009, covariance :-0.000\n",
    "            ######## ST Features\n",
    "            np.nanquantile(\n",
    "                [i[10] for i in processedHandTrainDataset.gsrFeatures[index_n_entries]], q=0.95),\n",
    "        ]\n",
    "\n",
    "    return dataset_features\n",
    "\n",
    "\n",
    "def experimentClassifier(clf, dataset, datasetLabels, nrOfIters=1, binarizeOutputLabels=False, binarizeAllLabels=False):\n",
    "    sgkf = model_selection.StratifiedKFold(n_splits=3, shuffle=False)\n",
    "\n",
    "    for trainIndexes, testIndexes in sgkf.split(dataset, datasetLabels):\n",
    "        kfold_train_dataset = dataset[trainIndexes]\n",
    "        kfold_train_dataset_labels = datasetLabels[trainIndexes]\n",
    "        kfold_test_dataset = dataset[testIndexes]\n",
    "        kfold_test_dataset_labels = datasetLabels[testIndexes]\n",
    "\n",
    "        if binarizeAllLabels:\n",
    "            kfold_train_dataset_labels = np.where(\n",
    "                kfold_train_dataset_labels == 0, 0, 1)\n",
    "            kfold_test_dataset_labels = np.where(\n",
    "                kfold_test_dataset_labels == 0, 0, 1)\n",
    "\n",
    "        clf.fit(kfold_train_dataset, kfold_train_dataset_labels)\n",
    "        kfold_predicted_labels = clf.predict(kfold_test_dataset)\n",
    "\n",
    "        #Printing results\n",
    "        if binarizeOutputLabels or binarizeAllLabels:\n",
    "            Logger.logPredictionMetrics(np.where(\n",
    "                kfold_test_dataset_labels == 0, 0, 1), np.where(kfold_predicted_labels == 0, 0, 1))\n",
    "        else:\n",
    "            Logger.logPredictionMetrics(\n",
    "                kfold_test_dataset_labels, kfold_predicted_labels)\n",
    "\n",
    "        nrOfIters = nrOfIters-1\n",
    "        if nrOfIters == 0:\n",
    "            break\n",
    "\n",
    "def fitAndPredictClassifier(clf, trainDataset, trainDatasetLabels, testDataset, testDatasetLabels=None, binarizeLabels=True, printMetrics=False, saveOutputFile=True):\n",
    "    sgkf = model_selection.StratifiedKFold(n_splits=2, shuffle=False,)\n",
    "\n",
    "    #clf.fit(trainDataset, trainDatasetLabels)\n",
    "    predicted_labels = clf.predict(testDataset)\n",
    "\n",
    "    if printMetrics:\n",
    "        Logger.logPredictionMetrics(testDatasetLabels, predicted_labels)\n",
    "\n",
    "    if binarizeLabels:\n",
    "        predicted_labels = np.where(predicted_labels == 0, 0, 1)\n",
    "\n",
    "    if saveOutputFile:\n",
    "        np.savetxt('/data/answer.txt', predicted_labels, fmt='%i')\n",
    "\n",
    "def reg_m(x, y):\n",
    "    ones = np.ones(len(x[0]))\n",
    "    X = sm.add_constant(np.column_stack((x[0], ones)))\n",
    "    for ele in x[1:]:\n",
    "        X = sm.add_constant(np.column_stack((ele, X)))\n",
    "    results = sm.OLS(y, x).fit()\n",
    "    return results\n",
    "\n",
    "def balanced_subsample(x, y, subsample_size=1.0):\n",
    "\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for ci, this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            np.random.shuffle(this_xs)\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = np.concatenate(xs)\n",
    "    ys = np.concatenate(ys)\n",
    "\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------  PROCESS DATA  -------------- #\n",
    "\n",
    "processedHandTrainDataset = filterZerosHandCraftedFeatures(\n",
    "    ds_train_handcrafted_features, ds_train_labels)\n",
    "\n",
    "trainDatasetTest = discretizeHandCraftedDataset(processedHandTrainDataset)\n",
    "\n",
    "startTrainIndex = 0\n",
    "endTrainIndex = len(trainDatasetTest)\n",
    "\n",
    "trainDataset = trainDatasetTest[startTrainIndex:endTrainIndex]\n",
    "trainDatasetLabels = np.where(processedHandTrainDataset.labels[startTrainIndex:endTrainIndex]==0,0,1)\n",
    "\n",
    "trainDataset, trainDatasetLabels= balanced_subsample(trainDataset,trainDatasetLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "importanceModel = DecisionTreeRegressor()\n",
    "# fit the model\n",
    "importanceModel.fit(trainDataset, trainDatasetLabels)\n",
    "# get importance\n",
    "importance = importanceModel.feature_importances_\n",
    "importance=np.sort(importance)\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    #Useful to remove features that wont be used for the model\n",
    "    print('Feature: %0d, Importance Score: %.5f' % (i, v))\n",
    "\n",
    "#for featureIndex in range(len(trainDataset[0])) :\n",
    "#corr, _ = pearsonr(dataset_handcrafted_masking.flatten() , dataset_deep_masking.flatten())\n",
    "#covariance= np.cov(dataset_handcrafted_masking.flatten(), dataset_deep_masking.flatten())[0][1]\n",
    "#print('Feature: %0d, Pearsons correlation: %.3f, covariance :%.3f' % (0, corr,covariance))\n",
    "\n",
    "#for featureIndex in range(len(trainDataset[0])) :\n",
    "#    corr, _ = pearsonr([i[featureIndex] for i in trainDataset], binarizedTrainLabels)\n",
    "#    covariance= np.cov([i[featureIndex] for i in trainDataset], binarizedTrainLabels)[0][1]\n",
    "#    print('Feature: %0d, Pearsons correlation: %.3f, covariance :%.3f' % (featureIndex, corr,covariance))\n",
    "#print(reg_m(trainDataset, trainDatasetLabels).summary())\n",
    "\n",
    "FeatureLogger.logFeatureRankings(trainDataset,trainDatasetLabels)\n",
    "FeatureLogger.logFeaturesCorrelation(trainDataset,trainDatasetLabels)\n",
    "\n",
    "#exit(0)\n",
    "#clf = tree.DecisionTreeClassifier(class_weight=[{0: 1, 1: 5}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 1}, {0: 1, 1: 0}])\n",
    "#clf = tree.DecisionTreeClassifier(class_weight={0: 2, 1: 1, 2: 2, 3: 3}) #0.54\n",
    "#clf = RandomForestClassifier(max_depth=18,max_features='log2')\n",
    "#clf = RandomForestClassifier(min_samples_leaf=10,max_depth=10, max_features=None) #BEST CLASSIFIER SO FAR - 0.45\n",
    "clf = svm.LinearSVC(class_weight={0:1.2,1:1,3:0,4:1}) # 0.53\n",
    "\n",
    "experimentClassifier(clf, trainDataset, trainDatasetLabels,nrOfIters=3, binarizeAllLabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------  TESTING  -------------- #\n",
    "\n",
    "ds_test_handcrafted_features = dataset['test']['hand_crafted_features']\n",
    "ds_test_labels = dataset['test']['labels']\n",
    "processedHandTestDataset=filterZerosHandCraftedFeatures(ds_test_handcrafted_features,ds_test_labels,filterZeros=False)\n",
    "\n",
    "testDatasetTest = discretizeHandCraftedDataset(processedHandTestDataset)\n",
    "\n",
    "fitAndPredictClassifier(clf, trainDataset, trainDatasetLabels, testDatasetTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
